{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E1jQV6SHHrI"
      },
      "source": [
        "# Running suite2p on example data\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MouseLand/suite2p/blob/main/notebooks/example_run_suite2p_2026.ipynb)\n",
        "\n",
        "This notebook will guide you through the various stages and outputs of suite2p by running it on a real-life dataset. This is data collected from a wild-type mouse injected with GCaMP6s in primary visual cortex. The recording was collected at 13Hz (there were 3 planes in the recording, 1 is included here).\n",
        "\n",
        "The code cell below installs and imports the necessary packages to use suite2p in this Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use the GPU-acceleration, connect to a hosted runtime with a GPU in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB9wKPiJG04m",
        "outputId": "a540cd36-0234-4524-8658-a94946e6e815"
      },
      "outputs": [],
      "source": [
        "!pip install suite2p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6ndUVDwHAlT"
      },
      "outputs": [],
      "source": [
        "import os, requests\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import suite2p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJD1-Js4HFQ4",
        "outputId": "82649171-2090-4529-d364-d91108bf37de"
      },
      "outputs": [],
      "source": [
        "# Figure Style settings for notebook.\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams.update({\n",
        "    'axes.spines.left': True,\n",
        "    'axes.spines.bottom': True,\n",
        "    'axes.spines.top': False,\n",
        "    'axes.spines.right': False,\n",
        "    'legend.frameon': False,\n",
        "    'figure.subplot.wspace': .01,\n",
        "    'figure.subplot.hspace': .01,\n",
        "    'figure.figsize': (18, 13),\n",
        "    'ytick.major.left': True,\n",
        "})\n",
        "jet = mpl.cm.get_cmap('jet')\n",
        "jet.set_bad(color='k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBB7xp1rHWGi"
      },
      "source": [
        "The next code cell downloads the data. You can also upload your own data to this folder on the left in the \"Files\" menu, or you can connect to your google drive (see instructions [here](https://colab.research.google.com/notebooks/io.ipynb)), which will make it easier to download the output files to your local computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOWs_8jSICr5",
        "outputId": "c6692d00-5246-4ebf-825f-77017a861b78"
      },
      "outputs": [],
      "source": [
        "# Run this cell if you'd like to connect/mount your google drive\n",
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjnUd83BHFu5",
        "outputId": "75160778-c7de-467e-8864-6e1a312d32e2"
      },
      "outputs": [],
      "source": [
        "fname = \"gt1.tif\"\n",
        "url = \"https://osf.io/download/67f0170c14be54fb766ddbb6\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "        print(\"Successfully downloaded data !!!\")\n",
        "from tifffile import imread\n",
        "from pathlib import Path\n",
        "data = imread(fname)\n",
        "print('imaging data of shape: ', data.shape)\n",
        "n_time, Ly, Lx = data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q03O0LcTRKn5"
      },
      "source": [
        "## Set db parameters\n",
        "\n",
        "db contains configurations related to output directory paths (e.g., `save_path0`: where you want to save suite2p output) and your recording setup (e.g., `nplanes`: number of planes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS6aqCFoH284",
        "outputId": "4d2d1d64-ca2d-441b-fbec-0b236fb56539"
      },
      "outputs": [],
      "source": [
        "db = {\n",
        "    \"data_path\": ['.'], # Directory where your input files are located\n",
        "    \"save_path0\": '/content/suite2p_output', # Directory where you want suite2p to write output files.\n",
        "    \"file_list\": [fname], # Specify files you'd like to specifically use in the data_path\n",
        "    \"input_format\": \"tif\",\n",
        "    \"nplanes\": 1, # each tiff has these many planes in sequence\n",
        "    \"nchannels\": 1, # each tiff has these many channels per plane\n",
        "    \"keep_movie_raw\": True,\n",
        "    \"batch_size\": 200, # we will decrease the batch_size in case low RAM on computer\n",
        "}\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdm-BHUtS8xn"
      },
      "source": [
        "## Set pipeline settings\n",
        "\n",
        "settings will contain the pipeline-specific parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdHENYRaSbhw",
        "outputId": "f33734ec-3e70-417d-ec3d-282a4afa0061"
      },
      "outputs": [],
      "source": [
        "settings = suite2p.default_settings()\n",
        "settings['detection']['threshold_scaling'] = 2.0 # we are increasing the threshold for finding ROIs to limit the number of non-cell ROIs found (sometimes useful in gcamp injections)\n",
        "settings['fs'] = 13 # sampling rate of recording, determines binning for cell detection\n",
        "settings['tau'] = 1.25 # timescale of gcamp to use for deconvolution\n",
        "settings['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' # use GPU if available for faster processing\n",
        "print(settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0PWtXjOTcKt"
      },
      "source": [
        "`settings` is a nested dictionary that contains module-specific dictionaries (e.g., registration, detection, classification, extraction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9amqr-7TV7P",
        "outputId": "7f816ead-588d-484a-8c33-bf4c82cb6c39"
      },
      "outputs": [],
      "source": [
        "print(settings.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKdmYYHMTpjd"
      },
      "source": [
        "## Run entire suite2p pipeline on data\n",
        "The suite2p.run_s2p function runs the pipeline and returns a list of output dictionaries containing the pipeline parameters used and extra data calculated along the way, one for each plane.\n",
        "\n",
        "To see the logs during running, you now need to run `logger_setup`, optionally providing the `save_path` for the logs to be written to a text file.\n",
        "\n",
        "The following cell might take a couple of minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNZteCzWTHEJ",
        "outputId": "906ccae6-0134-48d3-c4e9-9fb95cac4bb7"
      },
      "outputs": [],
      "source": [
        "from suite2p.run_s2p import logger_setup\n",
        "logger_setup()\n",
        "suite2p.run_s2p(settings=settings, db=db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_DcPQj2Up1Q"
      },
      "source": [
        "### Outputs from the Suite2p Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAiFOb1HVWUn"
      },
      "source": [
        "#### Results Files\n",
        "Analysis result files can be found below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfZzJyslZism",
        "outputId": "b21662d0-cac4-453e-bd64-49b6aa3b4fe8"
      },
      "outputs": [],
      "source": [
        "list(Path(db['save_path0']).joinpath('suite2p').iterdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fILI6TAWVSgG"
      },
      "source": [
        "## Running individual Suite2P modules\n",
        "\n",
        "While `suite2p.run_s2p` runs the entire pipeline, you may instead want to run individual modules (e.g., registration, cell detection, extraction, etc.). In this section, we'll go over the steps to run the following individual modules.\n",
        "\n",
        "*   Registration\n",
        "*   ROI detection\n",
        "* Signal Extraction\n",
        "* Classification of ROIs\n",
        "* Spike Deconvolution\n",
        "\n",
        "### Running Registration\n",
        "\n",
        "To run `registration`, `detection`, and `extraction` separately, we must first talk about a special class in suite2p called a `BinaryFile`. You can think of `BinaryFile` as a class for reading/writing image data that acts like a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtbvKry7aVTr",
        "outputId": "38e580c2-d1e2-4191-f396-ec5e0e5c5981"
      },
      "outputs": [],
      "source": [
        "from suite2p.io import BinaryFile\n",
        "\n",
        "# Convert our example tif file into a binary file\n",
        "if data.dtype == np.uint16:\n",
        "    data = (data // 2).astype(np.int16)\n",
        "# Write to binary\n",
        "data.tofile('raw_data.bin')\n",
        "f_raw = BinaryFile(Ly=Ly, Lx=Lx, filename='raw_data.bin')\n",
        "print(f_raw.shape)\n",
        "\n",
        "# Create a binary file we will write our registered image to\n",
        "f_reg = suite2p.io.BinaryFile(\n",
        "    Ly=Ly, Lx=Lx, filename='registered_data.bin',\n",
        "    n_frames = f_raw.shape[0], write=True\n",
        ") # Set registered binary file to have same n_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecsrWB1uc8oc"
      },
      "source": [
        "We'll run the registration module only on our example image which only contains data from a single channel. You can add in data for the second channel (e.g., `f_reg_chan2` and `f_raw_chan2`) using similar code to what we have above. When writing a new BinaryFile, please make sure to specify the number of frames your `BinaryFile` instance will have. Refer to the docs to see what the outputs refer to.\n",
        "\n",
        "If you have access to a CUDA-compatible GPU, make sure to set `device=torch.device(\"cuda\")`. Set it to `device=torch.device(\"cpu\")` if you do not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y4_QCJJhbvV"
      },
      "outputs": [],
      "source": [
        "settings['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' # use GPU if available for faster processing\n",
        "device = torch.device(settings['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nK8SeOMc8ct",
        "outputId": "42048d76-86d1-4663-f8f2-76aa50c7cb95"
      },
      "outputs": [],
      "source": [
        "from suite2p import registration\n",
        "\n",
        "reg_outputs = registration.registration_wrapper(\n",
        "  f_reg, f_raw=f_raw, f_reg_chan2=None, f_raw_chan2=None,\n",
        "  align_by_chan2=None, save_path= db['save_path0'],\n",
        "  badframes=None, settings=settings[\"registration\"],\n",
        "  device=device\n",
        ")\n",
        "f_reg.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX58VofIgaBY"
      },
      "source": [
        "`reg_outputs` will be a dictionary that contains the outputs of registration. Please refer to the docs to see what each key refers to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LBgIPEFgBl2",
        "outputId": "5b45f117-af9f-41dd-f7c2-e56b147f773d"
      },
      "outputs": [],
      "source": [
        "reg_outputs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPMF5sV5ehqC"
      },
      "source": [
        "### Running Detection\n",
        "\n",
        "To run ROI detection alone (called by the `detection_wrapper` function in the detection module), we'll first instantiate the necessary parameters. You only need a `BinaryRWFile` corresponding to a registered/unregistered recording. Here, we'll pass the `f_reg` we obtained after running the registration module above.\n",
        "\n",
        "Suite2p provides a default classification file containing a default dataset that is used to train a classifier that will be used for your data. One could specify their own classification file if they'd like. To do so, they should save a numpy file with a dict containing the following keys:\n",
        "\n",
        "\n",
        "* `stats`: ROI stats\n",
        "* `keys`: keys of ROI stats that will be used for classification\n",
        "* `iscell`: labels specifying whether an ROI is a cell or not\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pDxJvO4cX5W",
        "outputId": "4e6378b8-f108-47d9-b049-8e9e7fc56d30"
      },
      "outputs": [],
      "source": [
        "# Use default classification file provided by suite2p\n",
        "classfile = suite2p.classification.builtin_classfile\n",
        "np.load(classfile, allow_pickle=True)[()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OXO0RwqgwPM",
        "outputId": "422c8227-5160-42c2-b48a-73d822e15dcd"
      },
      "outputs": [],
      "source": [
        "from suite2p import detection\n",
        "\n",
        "yrange, xrange = reg_outputs[\"yrange\"], reg_outputs[\"xrange\"]\n",
        "# Check f_reg before detection\n",
        "f_reg = BinaryFile(Ly=Ly, Lx=Lx, filename='registered_data.bin')\n",
        "\n",
        "detect_outputs, stat, redcell = detection.detection_wrapper(\n",
        "    f_reg, meanImg_chan2=None,\n",
        "    yrange=yrange, xrange=xrange,\n",
        "    tau=settings[\"tau\"], fs=settings[\"fs\"],\n",
        "    diameter=settings[\"diameter\"],\n",
        "    settings=settings[\"detection\"],\n",
        "    classifier_path=classfile,\n",
        "    badframes=None,\n",
        "    preclassify=settings[\"classification\"][\"preclassify\"],\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfb76TuEiKIU"
      },
      "source": [
        "`detect_outputs` will contain configurations that were used for detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr7P2DTXhsAE",
        "outputId": "3377bafc-035e-4d3f-b6e3-dac3cffa37d1"
      },
      "outputs": [],
      "source": [
        "detect_outputs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9SUBkgJjzxO"
      },
      "source": [
        "`stat` will be an array of detected ROIs. `redcell` will be a binary array of shape `num_detected_rois` x 2. The first column will be a binary variable that specifies whether or not the detected ROI is an anatomical channel. The second column will be a measure of the confidence of the algorithm. `redcell` will be `None` if you do not have a second channel (i.e., `meanImg_chan2=None`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k17HxxPjSih",
        "outputId": "f9684052-4da6-4a9a-db26-74bde50ad6a0"
      },
      "outputs": [],
      "source": [
        "print(len(stat))\n",
        "stat[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsI5UHuzk51G"
      },
      "source": [
        "### Running Fluorescence Extraction\n",
        "\n",
        "To run extraction alone (called by the `extraction_wrapper` function in the extraction module), we can just make use of any `stat` dictionary (from previous runs of suite2p or a custom user-made one). In this case, we'll use the one output by the cell above. If you'd like to extract signal, you can pass a `binaryFile` corresponding to the recording for the second channel to the `f_reg_chan2` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmV6awagklGg"
      },
      "outputs": [],
      "source": [
        "from suite2p import extraction\n",
        "\n",
        "F, Fneu, F_chan2, Fneu_chan2 = extraction.extraction_wrapper(\n",
        "    stat, f_reg, f_reg_chan2=None, settings=settings[\"extraction\"],\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYiTcLdFlq9V"
      },
      "source": [
        "`F` will be a matrix of shape `num_detected_ROIs` x `n_time`. It contains the calcium signal extracted from each detected ROI. `Fneu` will have the same shape and will contain the background signal detected from the surrounding neuropil. `F_chan2` and `F_neu_chan2` will be similar outputs for the anatomical channel, if provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-sbzZedlOZp"
      },
      "outputs": [],
      "source": [
        "print(F.shape, Fneu.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FheSp3IsmaLf"
      },
      "source": [
        "### Running Spike Deconvolution\n",
        "\n",
        "We have to do some preprocessing before running spike deconvolution:\n",
        "\n",
        "\n",
        "1.   Neuropil subtraction\n",
        "2.   Baseline Correction\n",
        "\n",
        "You can read more about these steps in the docs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08yXX2A3mcmN"
      },
      "outputs": [],
      "source": [
        "# Neuropil subtraction\n",
        "dF = F.copy() - settings[\"extraction\"][\"neuropil_coefficient\"] * Fneu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXdo7AY7Y_O1"
      },
      "outputs": [],
      "source": [
        "# Baseline correction of fluorescence traces\n",
        "dF = extraction.preprocess(F=dF, fs=settings[\"fs\"], device=device,\n",
        "                           batch_size=settings[\"extraction\"][\"batch_size\"],\n",
        "                           **settings[\"dcnv_preprocess\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2IarjpCZSYq"
      },
      "outputs": [],
      "source": [
        "spks = extraction.oasis(F=dF, batch_size=settings[\"extraction\"][\"batch_size\"],\n",
        "                        tau=settings[\"tau\"], fs=settings[\"fs\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnDxBPFfm-48"
      },
      "source": [
        "### Running Classification of ROIs\n",
        "\n",
        "Finally, we can use activity-based statistics from the extraction step to classify ROIs as cells or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_25mFASrnBhB"
      },
      "outputs": [],
      "source": [
        "from suite2p import classification\n",
        "\n",
        "iscell = classification.classify(stat=stat, classfile=classfile)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du1wyq0wYWfE"
      },
      "source": [
        "`iscell` will be a num_ROIs x 2 array, where the first column is a 1 if it is a cell and 0 if not. The second column is the probability score given by the used classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ88XpqHYWME"
      },
      "outputs": [],
      "source": [
        "iscell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzEYNcJgac68"
      },
      "source": [
        "## Visualizations\n",
        "\n",
        "### Registration\n",
        "\n",
        "Registration computes a reference image from a subset of frames and registers all frames to the reference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf8AZG-SahGz"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 3, 1)\n",
        "\n",
        "plt.imshow(reg_outputs['refImg'], cmap='gray', )\n",
        "plt.title(\"Reference Image for Registration\");\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(reg_outputs['meanImg'], cmap='gray')\n",
        "plt.title(\"Mean registered image\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(reg_outputs['meanImgE'], cmap='gray')\n",
        "plt.title(\"High-pass filtered Mean registered image\");\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PakkNq6PbyjX"
      },
      "source": [
        "The rigid offsets of the frame from the reference are saved in `reg_outputs['yoff']` and `reg_outputs['xoff']`. The nonrigid offsets are saved in `reg_outputs['yoff1']` and `reg_outputs['xoff1']`, and each column is the offsets for a block (default block size will be 128 x 128 pixels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmW6ArLNcx64"
      },
      "outputs": [],
      "source": [
        "block_num = 1 # feel free to vary to see other blocks'\n",
        "reg_outputs['yoff1'].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu2HHUcuaiXa"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(reg_outputs['yoff'][:1000])\n",
        "plt.ylabel('rigid y-offsets')\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(reg_outputs['xoff'][:1000])\n",
        "plt.ylabel('rigid x-offsets')\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(reg_outputs['yoff1'][:1000, block_num])\n",
        "plt.ylabel('nonrigid y-offsets')\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(reg_outputs['xoff1'][:1000, block_num])\n",
        "plt.ylabel('nonrigid x-offsets')\n",
        "plt.xlabel('frames')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOZ5KWr9ccZ0"
      },
      "outputs": [],
      "source": [
        "#@title Run cell to look at registered frames\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from suite2p.io import BinaryFile\n",
        "\n",
        "widget = widgets.IntSlider(\n",
        "    value=7,\n",
        "    min=0,\n",
        "    max=10,\n",
        "    step=1,\n",
        "    description='Test:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")\n",
        "\n",
        "\n",
        "def plot_frame(t):\n",
        "    with BinaryFile(Ly=Ly,\n",
        "                Lx=Lx,\n",
        "                filename='registered_data.bin') as f:\n",
        "        plt.imshow(f[t])\n",
        "\n",
        "interact(plot_frame, t=(0, n_time- 1, 1)); # zero-indexed so have to subtract 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkbmx7yWdltQ"
      },
      "source": [
        "Here in the notebook is not the best/fastest way to play the movie, you can play it in the suite2p GUI in the \"View registered binary\" player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc34bFKMdrws"
      },
      "source": [
        "### Detection\n",
        "\n",
        "ROIs are found by searching for sparse signals that are correlated spatially in the FOV. The ROIs are saved in stat.npy as a list of dictionaries which contain the pixels of the ROI and their weights (`stat['ypix']`, `stat['xpix']`, and `stat['lam']`). It also contains other spatial properties of the ROIs such as their aspect ratio and compactness, and properties of the signal such as the skewness of the fluorescence signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "733uAaWzdnk0"
      },
      "outputs": [],
      "source": [
        "save_path = Path(db['save_path0']).joinpath('suite2p/plane0')\n",
        "stats_file = save_path.joinpath('stat.npy')\n",
        "iscell = np.load(save_path.joinpath('iscell.npy'), allow_pickle=True)[:, 0].astype(int)\n",
        "stats = np.load(stats_file, allow_pickle=True)\n",
        "print(stats[0].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svJx1cCoeg6u"
      },
      "source": [
        "Some ROIs are defined as \"cells\" (somatic ROIs) or \"not cells\" (all other ROIs) depending on their properties, like skewness, compactness, etc. Below we will visualize the ROIs, but please open the files in the suite2p GUI for closer inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DywP5IHkd1qH"
      },
      "outputs": [],
      "source": [
        "n_cells = len(stats)\n",
        "\n",
        "h = np.random.rand(n_cells)\n",
        "hsvs = np.zeros((2, Ly, Lx, 3), dtype=np.float32)\n",
        "\n",
        "for i, stat in enumerate(stats):\n",
        "    ypix, xpix, lam = stat['ypix'], stat['xpix'], stat['lam']\n",
        "    hsvs[iscell[i], ypix, xpix, 0] = h[i]\n",
        "    hsvs[iscell[i], ypix, xpix, 1] = 1\n",
        "    hsvs[iscell[i], ypix, xpix, 2] = lam / lam.max()\n",
        "\n",
        "from colorsys import hsv_to_rgb\n",
        "rgbs = np.array([hsv_to_rgb(*hsv) for hsv in hsvs.reshape(-1, 3)]).reshape(hsvs.shape)\n",
        "\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(detect_outputs['max_proj'], cmap='gray')\n",
        "plt.title(\"Registered Image, Max Projection\")\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(rgbs[1])\n",
        "plt.title(\"All Cell ROIs\")\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(rgbs[0])\n",
        "plt.title(\"All non-Cell ROIs\");\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W2--UooenFi"
      },
      "source": [
        "### Extraction\n",
        "\n",
        "We will load in the fluorescence, the neuropil and the deconvolved traces, and visualize them for a few cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW96w0MLejby"
      },
      "outputs": [],
      "source": [
        "f_cells = np.load(save_path.joinpath('F.npy'))\n",
        "f_neuropils = np.load(save_path.joinpath('Fneu.npy'))\n",
        "spks = np.load(save_path.joinpath('spks.npy'))\n",
        "f_cells.shape, f_neuropils.shape, spks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbDC_9fZhExC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "plt.suptitle(\"Fluorescence and Deconvolved Traces for Different ROIs\", y=0.92);\n",
        "rois = np.arange(len(f_cells))[::200]\n",
        "for i, roi in enumerate(rois):\n",
        "    plt.subplot(len(rois), 1, i+1, )\n",
        "    f = f_cells[roi]\n",
        "    f_neu = f_neuropils[roi]\n",
        "    sp = spks[roi]\n",
        "    # Adjust spks range to match range of fluroescence traces\n",
        "    fmax = np.maximum(f.max(), f_neu.max())\n",
        "    fmin = np.minimum(f.min(), f_neu.min())\n",
        "    frange = fmax - fmin\n",
        "    sp /= sp.max()\n",
        "    sp *= frange\n",
        "    plt.plot(f, label=\"Cell Fluorescence\")\n",
        "    plt.plot(f_neu, label=\"Neuropil Fluorescence\")\n",
        "    plt.plot(sp + fmin, label=\"Deconvolved\")\n",
        "    plt.xticks(np.arange(0, f_cells.shape[1], f_cells.shape[1]/10))\n",
        "    plt.ylabel(f\"ROI {roi}\", rotation=0)\n",
        "    plt.xlabel(\"frame\")\n",
        "    if i == 0:\n",
        "        plt.legend(bbox_to_anchor=(0.93, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtKGRIz2hGcC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
